{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffb1295",
   "metadata": {},
   "source": [
    "### Importação de Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "badf6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "random.seed(2)\n",
    "import numpy as np\n",
    "from pyrsgis import raster\n",
    "from pyrsgis.ml import imageChipsFromFile\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import resample\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from pretty_confusion_matrix import pp_matrix_from_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48fd282",
   "metadata": {},
   "source": [
    "### Modificando design do jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_settings():\n",
    "    display(HTML('<style>.container {width:100% !important;}</style>'))\n",
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47191b",
   "metadata": {},
   "source": [
    "# ------------------------------------------------\n",
    "# --------(Criando Chips de Imagem)--------\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9b7de",
   "metadata": {},
   "source": [
    "### Váriaveis - Criando Chips de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "chipSize = 3\n",
    "epochsNumber = 30\n",
    "trainedModelDir = 'trained_models_' + str(chipSize) + 'by' + str(chipSize) + '_' + str(epochsNumber) + 'Epochs'\n",
    "featuresName = 'CNN_' + str(chipSize) + 'by' + str(chipSize) + '_features.npy'\n",
    "labelsName = 'CNN_' + str(chipSize) + 'by' + str(chipSize) + '_labels.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3aae60",
   "metadata": {},
   "source": [
    "### Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85109169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria diretório do treinamento\n",
    "if not os.path.exists(os.path.join(os.getcwd(), trainedModelDir)):\n",
    "    os.mkdir(os.path.join(os.getcwd(), trainedModelDir))\n",
    "os.chdir(trainedModelDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4275d7",
   "metadata": {},
   "source": [
    "### define the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file = r\"/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data/ImagemVIG.tif\"\n",
    "label_file = r\"/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data/ImagemRotulada_qgis.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b89a8",
   "metadata": {},
   "source": [
    "### create feature chips using pyrsgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbf259",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = imageChipsFromFile(feature_file, x_size=chipSize, y_size=chipSize)\n",
    "print(feature_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d4b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.rollaxis(features, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd11ff",
   "metadata": {},
   "source": [
    "### read the label file and reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ba414",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, labels = raster.read(label_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9776d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02860b",
   "metadata": {},
   "source": [
    "### print basic details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input features shape:', features.shape)\n",
    "print('\\nInput labels shape:', labels.shape)\n",
    "print('Values in input features, min: %d & max: %d' % (features.min(), features.max()))\n",
    "print('Values in input labels, min: %d & max: %d' % (labels.min(), labels.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b04970",
   "metadata": {},
   "source": [
    "### Save the arrays as .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c354ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), trainedModelDir)):\n",
    "    os.mkdir(os.path.join(os.getcwd(), trainedModelDir))\n",
    "\n",
    "np.save(featuresName, features)\n",
    "np.save(labelsName, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e57b4",
   "metadata": {},
   "source": [
    "# ------------------------------------------------\n",
    "# -------------(Treinando Modelo)------------\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc71fd0",
   "metadata": {},
   "source": [
    "### Variáveis - Treinando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb7487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chipSize = 19\n",
    "epochsNumber = 30\n",
    "batchsize = 512\n",
    "featuresName = 'CNN_' + str(chipSize) + 'by' + str(chipSize) + '_features.npy'\n",
    "labelsName = 'CNN_' + str(chipSize) + 'by' + str(chipSize) + '_labels.npy'\n",
    "trainedModelDir = 'trained_models_' + str(chipSize) + 'by' + str(chipSize) + '_' + str(epochsNumber) + 'Epochs'\n",
    "modelFile = trainedModelDir + '/200409_CNN_Builtup_' + str(chipSize)+ 'by' + str(chipSize) +'_' + str(epochsNumber) + 'Epochs_CNNScore{}_CNNErro{}.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95d324",
   "metadata": {},
   "source": [
    "### Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d5d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data')\n",
    "os.chdir(trainedModelDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb9f43",
   "metadata": {},
   "source": [
    "### Load arrays from .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8179e4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data/x/trained_models_13by13_100Epochs/CNN_13by13_features.npy\n",
      "/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data/x/trained_models_13by13_100Epochs/CNN_13by13_labels.npy\n"
     ]
    }
   ],
   "source": [
    "features = np.load(input())\n",
    "labels = np.load(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25822ac5",
   "metadata": {},
   "source": [
    "### Separate and balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b20d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in each class:\n",
      "Built: 233449, Unbuilt: 3321389\n"
     ]
    }
   ],
   "source": [
    "built_features = features[labels==1]\n",
    "built_labels = labels[labels==1]\n",
    "\n",
    "unbuilt_features = features[labels==0]\n",
    "unbuilt_labels = labels[labels==0]\n",
    "\n",
    "print('Number of records in each class:')\n",
    "print('Built: %d, Unbuilt: %d' % (built_labels.shape[0], unbuilt_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea866d85",
   "metadata": {},
   "source": [
    "### Downsample the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95fff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in balanced classes:\n",
      "Built: 233449, Unbuilt: 233449\n"
     ]
    }
   ],
   "source": [
    "unbuilt_features = resample(unbuilt_features,\n",
    "                            replace = False, # sample without replacement\n",
    "                            n_samples = built_features.shape[0], # match minority n\n",
    "                            random_state = 2)\n",
    "\n",
    "unbuilt_labels = resample(unbuilt_labels,\n",
    "                          replace = False, # sample without replacement\n",
    "                          n_samples = built_features.shape[0], # match minority n\n",
    "                          random_state = 2)\n",
    "\n",
    "print('Number of records in balanced classes:')\n",
    "print('Built: %d, Unbuilt: %d' % (built_labels.shape[0], unbuilt_labels.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b067a79",
   "metadata": {},
   "source": [
    "### Combine the balanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8eb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((built_features, unbuilt_features), axis=0)\n",
    "labels = np.concatenate((built_labels, unbuilt_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9096d",
   "metadata": {},
   "source": [
    "### Normalise the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aea77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New values in input features, min: 0 & max: 1\n"
     ]
    }
   ],
   "source": [
    "features = features / 255.0\n",
    "print('New values in input features, min: %d & max: %d' % (features.min(), features.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b862847",
   "metadata": {},
   "source": [
    "### Define the function to split features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d781e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(features, labels, trainProp=0.7):\n",
    "    dataSize = features.shape[0]\n",
    "    sliceIndex = int(dataSize*trainProp)\n",
    "    randIndex = np.arange(dataSize)\n",
    "    random.shuffle(randIndex)\n",
    "    train_x = features[[randIndex[:sliceIndex]], :, :, :][0]\n",
    "    test_x = features[[randIndex[sliceIndex:]], :, :, :][0]\n",
    "    train_y = labels[randIndex[:sliceIndex]]\n",
    "    test_y = labels[randIndex[sliceIndex:]]\n",
    "    return(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de05e4",
   "metadata": {},
   "source": [
    "### Call the function to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aad6b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dab000",
   "metadata": {},
   "source": [
    "### Transpose the features to channel last format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ef2260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:34:38.055145: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-25 23:34:38.055569: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped features: (326828, 13, 13, 4) (140070, 13, 13, 4)\n"
     ]
    }
   ],
   "source": [
    "train_x = tf.transpose(train_x, [0, 2, 3, 1])\n",
    "test_x = tf.transpose(test_x, [0, 2, 3, 1])\n",
    "print('Reshaped features:', train_x.shape, test_x.shape)\n",
    "_, rowSize, colSize, nBands = train_x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46577469",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1871bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 19, 19, 32)        160       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 19, 19, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 19, 19, 48)        1584      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 19, 19, 48)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 19, 19, 48)        2352      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 19, 19, 48)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 19, 19, 48)        2352      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 19, 19, 48)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 17328)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1109056   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,115,634\n",
      "Trainable params: 1,115,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=1, padding='valid', activation='relu', input_shape=(chipSize, chipSize, nBands)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(48, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(48, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(48, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer= 'rmsprop',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f61e6",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    history = model.fit(train_x, train_y, epochs=epochsNumber, batch_size=batchsize, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17400b15",
   "metadata": {},
   "source": [
    "### Plota o histórico da acurácia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Learning curve')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('curve_accuracy.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598803a",
   "metadata": {},
   "source": [
    "### Plota o Histórico de Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd859c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('curve_Loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be974c4",
   "metadata": {},
   "source": [
    "### Mostra a potuação da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92627dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luizramos/Repos/CNN - Deep Learning sensoreamento remoto/Data/x/trained_models_13by13_100Epochs/200409_CNN_Builtup_13by13_100Epochs_PScore0.845_RScore0.816_FScore0.830.h5\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d6751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 23:34:53.495267: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-25 23:34:53.585483: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Score: 0.83\n",
      "CNN Error: 0.17\n",
      "CNN Loss: 0.40\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "result_error = str(\"%.2f\"%(1-scores[1]))\n",
    "result = str(\"%.2f\"%(scores[1]))\n",
    "print(\"CNN Score:\", result)\n",
    "print(\"CNN Error:\", result_error)\n",
    "print(\"CNN Loss:\", str(\"%.2f\"%(scores[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14526bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39883357286453247, 0.8319054841995239]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ebe9c",
   "metadata": {},
   "source": [
    "### Salva o modelo no formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7497384",
   "metadata": {},
   "source": [
    "### Salva os pesos em HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b41791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_w.h5\")\n",
    "print(\"Modelo salvo no disco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92b7d2",
   "metadata": {},
   "source": [
    "### Salva os resultados da acurácia em arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "index = []\n",
    "for i in range(1, epochsNumber+1):\n",
    "    index.append(f'epoca{i}')\n",
    "result_train = pd.DataFrame(history.history['accuracy'], index=index)\n",
    "result_test = pd.DataFrame(history.history['val_accuracy'], index=index)\n",
    "result_train.to_csv('accuracy_trein.csv', header=False)\n",
    "result_test.to_csv('accuracy_test.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d0ffb",
   "metadata": {},
   "source": [
    "### Predict for test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da49e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    yTestPredicted = model.predict(test_x)\n",
    "    yTestPredicted = yTestPredicted[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48509e19",
   "metadata": {},
   "source": [
    "### Calculate and display the error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825341e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTestPredicted = (yTestPredicted>0.6).astype(int)\n",
    "cMatrix = confusion_matrix(test_y, yTestPredicted)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb49b36",
   "metadata": {},
   "source": [
    "### Matriz confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b862dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cMatrix, display_labels=['Não-coqueiro', 'coqueiro'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('nao_normalizado.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "cMatrixNormalized = cMatrix.astype('float') / cMatrix.sum(axis=1)[:, np.newaxis]\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cMatrixNormalized, display_labels=['Não-coqueiro', 'coqueiro'])\n",
    "disp2.plot(cmap=plt.cm.Blues)\n",
    "plt.savefig('normalizado.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce1c682",
   "metadata": {},
   "source": [
    "### Save the model to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(modelFile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02861b3c",
   "metadata": {},
   "source": [
    "# ------------------------------------------------\n",
    "# ---------(Predizendo novos dados)---------\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90c7eb",
   "metadata": {},
   "source": [
    "### Variáveis - Predizendo novos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ade01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chipSize = 19\n",
    "new_features_dtype = 'float32'\n",
    "epochsNumber = 10\n",
    "#trainedModelDir = 'trained_models_' + str(chipSize) + 'by' + str(chipSize) + '_' + str(epochsNumber) + 'Epochs'\n",
    "outFile = 'ImagemVIG_predicted_' + str(chipSize) + 'x' + str(chipSize) + '_' + str(epochsNumber) + 'Epochs_' + new_features_dtype + '.tif'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a69b142",
   "metadata": {},
   "source": [
    "### Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d68c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08debc0d",
   "metadata": {},
   "source": [
    "### Load a new multispectral image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, featuresHyderabad = raster.read(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1539ac8",
   "metadata": {},
   "source": [
    "### Generate image chips in the back-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f117874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNdataGenerator(mxBands, kSize):\n",
    "    mxBands = mxBands / 255.0\n",
    "    nBands, rows, cols = mxBands.shape\n",
    "    margin = math.floor(kSize/2)\n",
    "    mxBands = np.pad(mxBands, margin, mode='constant')[margin:-margin, :, :]\n",
    "\n",
    "    features = np.empty((rows*cols, kSize, kSize, nBands), dtype=new_features_dtype)\n",
    "\n",
    "    n = 0\n",
    "    for row in range(margin, rows+margin):\n",
    "        for col in range(margin, cols+margin):\n",
    "            feat = mxBands[:, row-margin:row+margin+1, col-margin:col+margin+1]\n",
    "\n",
    "            b1, b2, b3, b4 = feat\n",
    "            feat = np.dstack((b1, b2, b3, b4))\n",
    "\n",
    "            features[n, :, :, :] = feat\n",
    "            n += 1\n",
    "            \n",
    "    return(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50da98",
   "metadata": {},
   "source": [
    "### Call the function to generate features tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b370efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = CNNdataGenerator(featuresHyderabad, kSize=chipSize)\n",
    "print('Shape of the new features', new_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37451066",
   "metadata": {},
   "source": [
    "### Predict new data and export the probability raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    newPredicted = model.predict(new_features)\n",
    "    newPredicted = newPredicted[:,1]\n",
    "    prediction = np.reshape(newPredicted, (ds.RasterYSize, ds.RasterXSize))\n",
    "    prediction = np.where(prediction < 0.6, 0, prediction)\n",
    "    raster.export(prediction, ds, filename=outFile, dtype=str(new_features.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbac1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniforge",
   "language": "python",
   "name": "miniforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
